{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dce017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions and helpers\n",
    "import os, re, io, gzip, requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from scipy.stats import norm \n",
    "# Import helper functions from the stat_buoy_functions module (clean module name)\n",
    "from stat_buoy_helpers import (\n",
    "    list_station_files,\n",
    "    fetch_file,\n",
    "    read_stdmet_max,\n",
    "    read_stdmet_min,\n",
    "    collect_station_max,\n",
    "    collect_station_min,\n",
    "    read_stdmet,\n",
    "    load_station,\n",
    "    plot_dailymax_seasonal_cycle,\n",
    "    plot_heatmap,\n",
    "    plot_time_series_anomalies,\n",
    "    plot_variance,\n",
    "    plot_variance_skew,\n",
    "    # warm-season specific helpers\n",
    "    get_warm_season_data,\n",
    "    compute_warm_season_anomalies,\n",
    "    plot_warm_season_heatmap,\n",
    "    compare_stations_variance,\n",
    "    plot_warm_season_time_series\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a076b98d",
   "metadata": {},
   "source": [
    "# Multi-Buoy Temperature Analysis\n",
    "\n",
    "This notebook analyzes temperature patterns across multiple NDBC buoys using visualization functions from our statistical analysis toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31476a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for station 46001...\n",
      "ðŸ“¡ Found 53 files for station 46001\n",
      "âœ… Parsed 1974: 1411 valid rows.\n",
      "âœ… Parsed 1976: 2401 valid rows.\n",
      "âœ… Parsed 1975: 2889 valid rows.\n",
      "âœ… Parsed 1977: 3096 valid rows.\n",
      "âœ… Parsed 1972: 1889 valid rows.\n",
      "âœ… Parsed 1973: 1696 valid rows.\n",
      "âœ… Parsed 1978: 2941 valid rows.\n",
      "âœ… Parsed 1979: 3990 valid rows.\n",
      "âœ… Parsed 1982: 8544 valid rows.\n",
      "âœ… Parsed 1980: 8712 valid rows.\n",
      "âœ… Parsed 1981: 8608 valid rows.\n",
      "âœ… Parsed 1983: 8610 valid rows.\n",
      "âœ… Parsed 1984: 8665 valid rows.\n",
      "âœ… Parsed 1985: 8735 valid rows.\n",
      "âœ… Parsed 1986: 8691 valid rows.\n",
      "âœ… Parsed 1988: 8727 valid rows.\n",
      "âœ… Parsed 1990: 5185 valid rows.\n",
      "âœ… Parsed 1987: 8689 valid rows.\n",
      "âœ… Parsed 1989: 8723 valid rows.\n",
      "âœ… Parsed 1991: 8050 valid rows.\n",
      "âœ… Parsed 1992: 8666 valid rows.\n",
      "âœ… Parsed 1994: 1541 valid rows.\n",
      "âœ… Parsed 1993: 8172 valid rows.\n",
      "âœ… Parsed 1995: 3270 valid rows.\n",
      "âœ… Parsed 1997: 7910 valid rows.\n",
      "âœ… Parsed 1996: 8805 valid rows.\n",
      "âœ… Parsed 1999: 8663 valid rows.\n",
      "âœ… Parsed 1998: 8546 valid rows.\n",
      "âœ… Parsed 2000: 8697 valid rows.\n",
      "âœ… Parsed 2001: 8731 valid rows.\n",
      "âœ… Parsed 2002: 8705 valid rows.\n",
      "âœ… Parsed 2003: 8722 valid rows.\n",
      "âœ… Parsed 2004: 6023 valid rows.\n",
      "âœ… Parsed 2007: 3431 valid rows.\n",
      "âœ… Parsed 2005: 8750 valid rows.\n",
      "âœ… Parsed 2006: 7471 valid rows.\n",
      "âœ… Parsed 2010: 8686 valid rows.\n",
      "âœ… Parsed 2009: 8661 valid rows.\n",
      "âœ… Parsed 2008: 8672 valid rows.\n",
      "âœ… Parsed 2011: 8680 valid rows.\n",
      "âœ… Parsed 2012: 8702 valid rows.\n",
      "âœ… Parsed 2013: 2236 valid rows.\n",
      "âš ï¸ No valid ATMP data found for 2014.\n",
      "âœ… Parsed 2015: 4726 valid rows.\n",
      "âœ… Parsed 2016: 8752 valid rows.\n",
      "âœ… Parsed 2019: 5956 valid rows.\n",
      "âœ… Parsed 2017: 8742 valid rows.\n",
      "âœ… Parsed 2018: 8729 valid rows.\n",
      "âœ… Parsed 2020: 8640 valid rows.\n",
      "âœ… Parsed 2021: 6383 valid rows.\n",
      "âœ… Parsed 2022: 17897 valid rows.\n",
      "âœ… Parsed 2023: 29541 valid rows.\n",
      "âœ… Parsed 2024: 43989 valid rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:309: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(ATMP=g[\"ATMP\"].interpolate(limit_direction=\"both\")))\n",
      "c:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:313: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled[\"ATMP\"] = df_filled[\"ATMP\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous coverage from 1972â€“2024 (53 total years)\n",
      "Loading data for station 46014...\n",
      "ðŸ“¡ Found 44 files for station 46014\n",
      "âœ… Parsed 1981: 6051 valid rows.\n",
      "âœ… Parsed 1985: 7915 valid rows.\n",
      "âœ… Parsed 1983: 8475 valid rows.\n",
      "âœ… Parsed 1982: 8683 valid rows.\n",
      "âœ… Parsed 1986: 8679 valid rows.\n",
      "âœ… Parsed 1984: 8720 valid rows.\n",
      "âœ… Parsed 1987: 8572 valid rows.\n",
      "âœ… Parsed 1991: 6865 valid rows.\n",
      "âœ… Parsed 1988: 6515 valid rows.\n",
      "âœ… Parsed 1989: 7434 valid rows.\n",
      "âœ… Parsed 1992: 4837 valid rows.\n",
      "âœ… Parsed 1990: 8207 valid rows.\n",
      "âœ… Parsed 1993: 6051 valid rows.\n",
      "âœ… Parsed 1995: 7475 valid rows.\n",
      "âœ… Parsed 1994: 8622 valid rows.\n",
      "âœ… Parsed 1996: 8864 valid rows.\n",
      "âœ… Parsed 1997: 8668 valid rows.\n",
      "âœ… Parsed 1998: 8634 valid rows.\n",
      "âœ… Parsed 1999: 8513 valid rows.\n",
      "âœ… Parsed 2000: 8619 valid rows.\n",
      "âœ… Parsed 2001: 8714 valid rows.\n",
      "âœ… Parsed 2002: 7791 valid rows.\n",
      "âœ… Parsed 2003: 8743 valid rows.\n",
      "âœ… Parsed 2004: 8743 valid rows.\n",
      "âœ… Parsed 2006: 5429 valid rows.\n",
      "âœ… Parsed 2005: 8754 valid rows.\n",
      "âœ… Parsed 2007: 7776 valid rows.\n",
      "âœ… Parsed 2010: 8756 valid rows.\n",
      "âœ… Parsed 2008: 8754 valid rows.\n",
      "âœ… Parsed 2011: 5692 valid rows.\n",
      "âœ… Parsed 2012: 8752 valid rows.\n",
      "âœ… Parsed 2009: 8756 valid rows.\n",
      "âœ… Parsed 2013: 8727 valid rows.\n",
      "âœ… Parsed 2014: 8356 valid rows.\n",
      "âœ… Parsed 2015: 12397 valid rows.\n",
      "âœ… Parsed 2016: 52464 valid rows.\n",
      "âœ… Parsed 2018: 27963 valid rows.\n",
      "âœ… Parsed 2017: 28787 valid rows.\n",
      "âœ… Parsed 2020: 23264 valid rows.\n",
      "âœ… Parsed 2019: 52051 valid rows.\n",
      "âœ… Parsed 2021: 32713 valid rows.\n",
      "âœ… Parsed 2022: 51649 valid rows.\n",
      "âœ… Parsed 2023: 52426 valid rows.\n",
      "âœ… Parsed 2024: 52541 valid rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:309: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(ATMP=g[\"ATMP\"].interpolate(limit_direction=\"both\")))\n",
      "c:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:313: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled[\"ATMP\"] = df_filled[\"ATMP\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous coverage from 1981â€“2024 (44 total years)\n",
      "Loading data for station 46025...\n",
      "ðŸ“¡ Found 43 files for station 46025\n",
      "âœ… Parsed 1982: 6104 valid rows.\n",
      "âœ… Parsed 1986: 8173 valid rows.\n",
      "âœ… Parsed 1985: 8364 valid rows.\n",
      "âœ… Parsed 1987: 7894 valid rows.\n",
      "âœ… Parsed 1983: 8586 valid rows.\n",
      "âœ… Parsed 1984: 8016 valid rows.\n",
      "âœ… Parsed 1989: 5270 valid rows.\n",
      "âœ… Parsed 1988: 8723 valid rows.\n",
      "âœ… Parsed 1990: 7731 valid rows.\n",
      "âœ… Parsed 1991: 7943 valid rows.\n",
      "âœ… Parsed 1993: 8218 valid rows.\n",
      "âœ… Parsed 1992: 8704 valid rows.\n",
      "âœ… Parsed 1994: 7543 valid rows.\n",
      "âœ… Parsed 1997: 5423 valid rows.\n",
      "âœ… Parsed 1995: 7983 valid rows.\n",
      "âœ… Parsed 1996: 8762 valid rows.\n",
      "âœ… Parsed 1998: 8446 valid rows.\n",
      "âœ… Parsed 1999: 8636 valid rows.\n",
      "âœ… Parsed 2000: 8650 valid rows.\n",
      "âœ… Parsed 2001: 8665 valid rows.\n",
      "âœ… Parsed 2003: 8721 valid rows.\n",
      "âœ… Parsed 2002: 8667 valid rows.\n",
      "âœ… Parsed 2004: 8737 valid rows.\n",
      "âœ… Parsed 2005: 8739 valid rows.\n",
      "âœ… Parsed 2007: 8713 valid rows.\n",
      "âœ… Parsed 2006: 8728 valid rows.\n",
      "âœ… Parsed 2008: 8760 valid rows.\n",
      "âœ… Parsed 2009: 8759 valid rows.\n",
      "âœ… Parsed 2010: 8713 valid rows.\n",
      "âœ… Parsed 2012: 3701 valid rows.\n",
      "âœ… Parsed 2011: 8753 valid rows.\n",
      "âœ… Parsed 2013: 8669 valid rows.\n",
      "âœ… Parsed 2014: 8611 valid rows.\n",
      "âœ… Parsed 2015: 8751 valid rows.\n",
      "âœ… Parsed 2016: 27627 valid rows.\n",
      "âœ… Parsed 2018: 31634 valid rows.\n",
      "âœ… Parsed 2017: 27643 valid rows.\n",
      "âœ… Parsed 2020: 51194 valid rows.\n",
      "âœ… Parsed 2019: 52070 valid rows.\n",
      "âœ… Parsed 2021: 49441 valid rows.\n",
      "âœ… Parsed 2022: 52338 valid rows.\n",
      "âœ… Parsed 2024: 31323 valid rows.\n",
      "âœ… Parsed 2023: 52488 valid rows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:309: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(ATMP=g[\"ATMP\"].interpolate(limit_direction=\"both\")))\n",
      "c:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:313: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled[\"ATMP\"] = df_filled[\"ATMP\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous coverage from 1982â€“2024 (43 total years)\n",
      "Loading data for station desw1...\n",
      "ðŸ“¡ Found 41 files for station desw1\n",
      "âœ… Parsed 1984: 3302 valid rows.\n",
      "âœ… Parsed 1987: 8695 valid rows.\n",
      "âœ… Parsed 1986: 8694 valid rows.\n",
      "âœ… Parsed 1989: 8558 valid rows.\n",
      "âœ… Parsed 1985: 8661 valid rows.\n",
      "âœ… Parsed 1988: 8704 valid rows.\n",
      "âœ… Parsed 1990: 8718 valid rows.\n",
      "âœ… Parsed 1991: 8740 valid rows.\n",
      "âœ… Parsed 1992: 8662 valid rows.\n",
      "âœ… Parsed 1994: 8649 valid rows.\n",
      "âœ… Parsed 1995: 8687 valid rows.\n",
      "âœ… Parsed 1993: 8660 valid rows.\n",
      "âœ… Parsed 1997: 471 valid rows.\n",
      "âœ… Parsed 1996: 8833 valid rows.\n",
      "âœ… Parsed 1998: 8566 valid rows.\n",
      "âœ… Parsed 1999: 8377 valid rows.\n",
      "âœ… Parsed 2000: 8644 valid rows.\n",
      "âœ… Parsed 2001: 8683 valid rows.\n",
      "âœ… Parsed 2002: 8324 valid rows.\n",
      "âœ… Parsed 2003: 8476 valid rows.\n",
      "âœ… Parsed 2004: 8725 valid rows.\n",
      "âœ… Parsed 2005: 8707 valid rows.\n",
      "âœ… Parsed 2006: 8684 valid rows.\n",
      "âœ… Parsed 2007: 8683 valid rows.\n",
      "âœ… Parsed 2008: 8716 valid rows.\n",
      "âœ… Parsed 2009: 8703 valid rows.\n",
      "âœ… Parsed 2010: 7908 valid rows.\n",
      "âœ… Parsed 2012: 8756 valid rows.\n",
      "âœ… Parsed 2013: 8755 valid rows.\n",
      "âœ… Parsed 2011: 8525 valid rows.\n",
      "âœ… Parsed 2014: 8756 valid rows.\n",
      "âœ… Parsed 2015: 8759 valid rows.\n",
      "âœ… Parsed 2016: 8749 valid rows.\n",
      "âœ… Parsed 2019: 3404 valid rows.\n",
      "âœ… Parsed 2018: 7990 valid rows.\n",
      "âœ… Parsed 2017: 8751 valid rows.\n",
      "âœ… Parsed 2020: 8744 valid rows.\n",
      "âœ… Parsed 2021: 8570 valid rows.\n",
      "âœ… Parsed 2022: 3675 valid rows.\n",
      "âš ï¸ No valid ATMP data found for 2023.\n",
      "âš ï¸ No valid ATMP data found for 2024.\n",
      "continuous coverage from 1984â€“2022 (39 total years)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:309: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.assign(ATMP=g[\"ATMP\"].interpolate(limit_direction=\"both\")))\n",
      "c:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:313: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_filled[\"ATMP\"] = df_filled[\"ATMP\"].fillna(method=\"ffill\").fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "# Define buoy stations to analyze\n",
    "stations = [\"46001\", \"46014\", \"46025\", \"desw1\"]  # 3 california buoys + one washington\n",
    "\n",
    "# Load data for all stations\n",
    "station_data = {}\n",
    "for station in stations:\n",
    "    print(f\"Loading data for station {station}...\")\n",
    "    data = load_station(station)\n",
    "    if data is not None:\n",
    "        station_data[station] = data\n",
    "    else:\n",
    "        print(f\"Warning: No data available for station {station}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c699aaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(       year  day_of_year date  ATMP\n",
      "0      1972            1  NaT   NaN\n",
      "1      1972            2  NaT   NaN\n",
      "2      1972            3  NaT   NaN\n",
      "3      1972            4  NaT   NaN\n",
      "4      1972            5  NaT   NaN\n",
      "...     ...          ...  ...   ...\n",
      "19340  2024          361  NaT   NaN\n",
      "19341  2024          362  NaT   NaN\n",
      "19342  2024          363  NaT   NaN\n",
      "19343  2024          364  NaT   NaN\n",
      "19344  2024          365  NaT   NaN\n",
      "\n",
      "[19345 rows x 4 columns],     year  valid_percent\n",
      "0   1972          100.0\n",
      "1   1973          100.0\n",
      "2   1974          100.0\n",
      "3   1975          100.0\n",
      "4   1976          100.0\n",
      "5   1977          100.0\n",
      "6   1978          100.0\n",
      "7   1979          100.0\n",
      "8   1980          100.0\n",
      "9   1981          100.0\n",
      "10  1982          100.0\n",
      "11  1983          100.0\n",
      "12  1984          100.0\n",
      "13  1985          100.0\n",
      "14  1986          100.0\n",
      "15  1987          100.0\n",
      "16  1988          100.0\n",
      "17  1989          100.0\n",
      "18  1990          100.0\n",
      "19  1991          100.0\n",
      "20  1992          100.0\n",
      "21  1993          100.0\n",
      "22  1994          100.0\n",
      "23  1995          100.0\n",
      "24  1996          100.0\n",
      "25  1997          100.0\n",
      "26  1998          100.0\n",
      "27  1999          100.0\n",
      "28  2000          100.0\n",
      "29  2001          100.0\n",
      "30  2002          100.0\n",
      "31  2003          100.0\n",
      "32  2004          100.0\n",
      "33  2005          100.0\n",
      "34  2006          100.0\n",
      "35  2007          100.0\n",
      "36  2008          100.0\n",
      "37  2009          100.0\n",
      "38  2010          100.0\n",
      "39  2011          100.0\n",
      "40  2012          100.0\n",
      "41  2013          100.0\n",
      "42  2015          100.0\n",
      "43  2016          100.0\n",
      "44  2017          100.0\n",
      "45  2018          100.0\n",
      "46  2019          100.0\n",
      "47  2020          100.0\n",
      "48  2021          100.0\n",
      "49  2022          100.0\n",
      "50  2023          100.0\n",
      "51  2024          100.0)\n"
     ]
    }
   ],
   "source": [
    "print(station_data['46001'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcf713a",
   "metadata": {},
   "source": [
    "## Temperature Anomaly Analysis\n",
    "\n",
    "Compare temperature anomaly patterns across different buoy locations using heatmaps and time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1091d283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing warm-season temperature anomalies for station 46001\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAnalyzing warm-season temperature anomalies for station \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Warm-season heatmap (automatically finds climatological peak)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mplot_warm_season_heatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Warm-season annual anomaly time series\u001b[39;00m\n\u001b[32m      9\u001b[39m plot_warm_season_time_series(data, station, window_size=\u001b[32m50\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:445\u001b[39m, in \u001b[36mplot_warm_season_heatmap\u001b[39m\u001b[34m(df, station, window_size)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot_warm_season_heatmap\u001b[39m(df, station, window_size=\u001b[32m50\u001b[39m):\n\u001b[32m    444\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Plot heatmap of temperature anomalies limited to warm season.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m     anomalies, mean_cycle, (warm_start, warm_center, warm_end) = \u001b[43mcompute_warm_season_anomalies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m     plt.figure(figsize=(\u001b[32m12\u001b[39m,\u001b[32m6\u001b[39m))\n\u001b[32m    448\u001b[39m     plt.imshow(anomalies.T, aspect=\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m, cmap=\u001b[33m'\u001b[39m\u001b[33mcoolwarm\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    449\u001b[39m                extent=[warm_start, warm_end, anomalies.columns.min(), anomalies.columns.max()],\n\u001b[32m    450\u001b[39m                origin=\u001b[33m'\u001b[39m\u001b[33mlower\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:433\u001b[39m, in \u001b[36mcompute_warm_season_anomalies\u001b[39m\u001b[34m(df, window_size)\u001b[39m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_warm_season_anomalies\u001b[39m(df, window_size=\u001b[32m50\u001b[39m):\n\u001b[32m    425\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[33;03m    Compute anomaly pivot table restricted to the warm season.\u001b[39;00m\n\u001b[32m    427\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    431\u001b[39m \u001b[33;03m    - warm_period: (start, center, end)\u001b[39;00m\n\u001b[32m    432\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     warm_df, (warm_start, warm_center, warm_end) = \u001b[43mget_warm_season_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m     daily_maxes = warm_df.groupby([\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mday_of_year\u001b[39m\u001b[33m'\u001b[39m])[\u001b[33m'\u001b[39m\u001b[33mATMP\u001b[39m\u001b[33m'\u001b[39m].max().reset_index()\n\u001b[32m    435\u001b[39m     pivot = daily_maxes.pivot(index=\u001b[33m'\u001b[39m\u001b[33mday_of_year\u001b[39m\u001b[33m'\u001b[39m, columns=\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m, values=\u001b[33m'\u001b[39m\u001b[33mATMP\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ethan\\Zeppetello Research\\stat_buoy_helpers.py:411\u001b[39m, in \u001b[36mget_warm_season_data\u001b[39m\u001b[34m(df, window_size)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    394\u001b[39m \u001b[33;03mIdentify and extract warm season data based on climatological maximum.\u001b[39;00m\n\u001b[32m    395\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    408\u001b[39m \u001b[33;03m    (warm_start, warm_center, warm_end)\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    410\u001b[39m \u001b[38;5;66;03m# compute the multi-year daily mean using daily maxima\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m daily_max = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m([\u001b[33m\"\u001b[39m\u001b[33myear\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mday_of_year\u001b[39m\u001b[33m\"\u001b[39m])[\u001b[33m'\u001b[39m\u001b[33mATMP\u001b[39m\u001b[33m'\u001b[39m].max().reset_index()\n\u001b[32m    412\u001b[39m daily_mean = daily_max.groupby(\u001b[33m'\u001b[39m\u001b[33mday_of_year\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mATMP\u001b[39m\u001b[33m'\u001b[39m].mean()\n\u001b[32m    414\u001b[39m warm_center = \u001b[38;5;28mint\u001b[39m(daily_mean.idxmax())\n",
      "\u001b[31mAttributeError\u001b[39m: 'tuple' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "# Generate warm-season heatmaps and time series for each station\n",
    "for station, data in station_data.items():\n",
    "    print(f\"\\nAnalyzing warm-season temperature anomalies for station {station}\")\n",
    "\n",
    "    # Warm-season heatmap (automatically finds climatological peak)\n",
    "    plot_warm_season_heatmap(data, station, window_size=50)\n",
    "\n",
    "    # Warm-season annual anomaly time series\n",
    "    plot_warm_season_time_series(data, station, window_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7fce5e",
   "metadata": {},
   "source": [
    "## Seasonal Variance Analysis\n",
    "\n",
    "Analyze how temperature variability changes throughout the year at different buoy locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7f47f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare variance and skew across the loaded stations (side-by-side)\n",
    "# Use the order in station_data (preserves your load order)\n",
    "compare_stations_variance(station_data, stations=list(station_data.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze variance patterns for each station\n",
    "for station, data in station_data.items():\n",
    "    print(f\"\\nAnalyzing variance patterns for station {station}\")\n",
    "    \n",
    "    # Plot seasonal variance\n",
    "    plot_variance(data, station)\n",
    "    \n",
    "    # Plot monthly distribution characteristics\n",
    "    plot_variance_skew(data, station)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zepp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
